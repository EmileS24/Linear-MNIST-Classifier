{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import trange\n",
        "import matplotlib.pyplot as plot\n",
        "import torchvision.datasets as datastore\n",
        "import time\n",
        "\n",
        "# Load the MNIST dataset\n",
        "datastore.MNIST('./data', train=True, download=True)\n",
        "datastore.MNIST('./data', train=False, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r39xyKP3G_LI",
        "outputId": "c055ce98-92ab-488f-d3c3-9f47282fb8d0"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: ./data\n",
              "    Split: Test"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to load data as a numpy array\n",
        "def getData(file):\n",
        "    f = open(file, 'rb').read()\n",
        "    return np.frombuffer(f, dtype=np.uint8).copy()"
      ],
      "metadata": {
        "id": "FD5Czk4XHCGZ"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the load data method and get the images in stored in the following format as mentioned in \n",
        "# the assignment pdf[total images x (784)] for training and test data\n",
        "# We also have to ignore the 0x10 i.e. 16 bytes metadata from image\n",
        "\n",
        "imageTraining = getData('./data/MNIST/raw/train-images-idx3-ubyte')[0x10:].reshape(-1, 784)\n",
        "imageTesting = getData('./data/MNIST/raw/t10k-images-idx3-ubyte')[0x10:].reshape(-1, 784)\n",
        "\n",
        "# Ignore the 8 bytes metadata from label data, when loading the training and test labels\n",
        "labelsTraining = getData('./data/MNIST/raw/train-labels-idx1-ubyte')[8:]\n",
        "labelsTesting = getData('./data/MNIST/raw/t10k-labels-idx1-ubyte')[8:]\n",
        "\n",
        "print(imageTraining.shape, labelsTraining.shape)\n",
        "print(imageTesting.shape, labelsTesting.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD0jtzpOHGPm",
        "outputId": "992cb792-2f2f-4489-de13-647e54fa7459"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784) (60000,)\n",
            "(10000, 784) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create one hot matrix for the training labels\n",
        "# Initialize the matrix to zeroes, for [60000 x 10] training data\n",
        "onehotTraining = np.zeros((labelsTraining.shape[0], 10), np.float32)\n",
        "# Set the correct position value to 1\n",
        "onehotTraining[range(onehotTraining.shape[0]), labelsTraining] = 1\n",
        "\n",
        "# Create one hot matrix for the testing labels\n",
        "# Initialize the matrix to zeroes, for [60000 x 10] training data\n",
        "onehotTesting = np.zeros((labelsTesting.shape[0], 10), np.float32)\n",
        "# Set the correct position to 1\n",
        "onehotTesting[range(onehotTesting.shape[0]), labelsTesting] = 1\n",
        "\n",
        "print(onehotTraining.shape, onehotTesting.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBATTB3SHLAY",
        "outputId": "bfc616b6-f720-40bd-fffd-5b021e412cc3"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 10) (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameters\n",
        "batchSize = 1000\n",
        "numOfEpochs = 400\n",
        "learningRate = 0.000000075\n",
        "\n",
        "#Initialize the weight matrix, which is to be learned as zeroes\n",
        "\n",
        "Weights = np.zeros((784, 10))\n",
        "\n",
        "print(Weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrRSj_VUHQyj",
        "outputId": "73eeb121-f2d3-48b8-f874-12644aaa4e15"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to compute the gradient and update the weight matrix using it and the learning rate defined above\n",
        "def forward(images, labels, Weights):\n",
        "    gradient = images.T.dot(images.dot(Weights) - labels) / batchSize\n",
        "    Weights = Weights - (learningRate * gradient)\n",
        "    return Weights"
      ],
      "metadata": {
        "id": "SbJR-dVzHUyM"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some lists to plot the graphs\n",
        "quadLosses = []\n",
        "testAccuracies = []\n",
        "epochs = []"
      ],
      "metadata": {
        "id": "gz4z0PxWMJ5Y"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INkUnY35EF4d"
      },
      "outputs": [],
      "source": [
        "# To count training time\n",
        "startCounter = time.time()\n",
        "\n",
        "#for section 5\n",
        "# newSample = np.random.choice(60000,size=500,replace=False) \n",
        "# sample = imageTraining[newSample]\n",
        "\n",
        "# Stochastic gradient descent implementations\n",
        "for i in range(numOfEpochs):\n",
        "    epochs.append(i)      # To plot graphs\n",
        "\n",
        "    # select batchSize numbers uniformly, randomly and with replacement to train\n",
        "    batch = np.random.randint(1, 60000, size=(batchSize))\n",
        "    # for section 5\n",
        "    # batch = np.random.randint(1, 500, size=(batchSize))\n",
        "    # images = sample[batch]\n",
        "\n",
        "    # select the images corresponding to them from training dataset\n",
        "    images = imageTraining[batch]\n",
        "    # select the corresponding one-hot labels from training labels\n",
        "    labels = onehotTraining[batch]\n",
        "\n",
        "    # Call the forward method to update the weights\n",
        "    Weights = forward(images, labels, Weights)\n",
        "    predictedLabels = images.dot(Weights)\n",
        "    quadraticLoss = np.sum((labels - predictedLabels)**2) / batchSize\n",
        "    quadLosses.append(quadraticLoss)      # To plot graphs\n",
        "    #print(quadraticLoss)\n",
        "\n",
        "    # predict the labels on the training dataset\n",
        "    predictedTrainingLabels = imageTraining.dot(Weights)\n",
        "    # compute the training accuracy\n",
        "    trainingAccu = np.sum(labelsTraining == np.argmax(predictedTrainingLabels, axis=1)) / labelsTraining.shape[0]\n",
        "    \n",
        "    # predict the labels on the test dataset\n",
        "    predictedTestingLabels = imageTesting.dot(Weights)\n",
        "    # compute the testing accuracy\n",
        "    testingAccu = np.sum(labelsTesting == np.argmax(predictedTestingLabels, axis=1)) / labelsTesting.shape[0]\n",
        "\n",
        "    # To plot graphs\n",
        "    testAccuracies.append(testingAccu)\n",
        " \n",
        "endCounter = time.time() - startCounter \n",
        "print('loss:' , quadraticLoss)\n",
        "print('accuracy:' , testingAccu)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot graph of test accuracy vs num of epochs\n",
        "plot.plot(epochs,testAccuracies)\n",
        "plot.xlabel('Epochs')\n",
        "plot.ylabel('Test Accuracy')\n",
        "plot.title('Test accuracy vs num of Epochs')\n",
        "plot.show()"
      ],
      "metadata": {
        "id": "-scqta6mNHPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot graph of training loss vs num of epochs \n",
        "plot.plot(epochs,quadLosses)\n",
        "plot.xlabel('Epochs')\n",
        "plot.ylabel('Quadratic Loss')\n",
        "plot.title('Loss vs num of Epochs')\n",
        "plot.show()"
      ],
      "metadata": {
        "id": "RNOAOhJkNkkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Training time\n",
        "print(endCounter)"
      ],
      "metadata": {
        "id": "eIw4kDG6P5mY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}